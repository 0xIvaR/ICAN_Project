"""
ICAN Demo Script
Demonstrates the capabilities of the ICAN model for face recognition and gender classification
"""

import os
import torch
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import cv2

from src.config import Config
from src.model import create_ican_model, count_parameters
from inference import ICANInference
from src.dataset import create_data_splits

def demo_model_architecture():
    """Demonstrate model architecture and capabilities"""
    print("ğŸ—ï¸  ICAN Model Architecture Demo")
    print("=" * 60)
    
    # Create model
    print("Creating ICAN model...")
    model = create_ican_model(num_identity_classes=100)
    
    # Model info
    total_params = count_parameters(model)
    print(f"âœ“ Model: {Config.MODEL_NAME}")
    print(f"âœ“ Backbone: {Config.BACKBONE}")
    print(f"âœ“ Input Size: {Config.IMG_SIZE}x{Config.IMG_SIZE}")
    print(f"âœ“ Total Parameters: {total_params:,}")
    print(f"âœ“ Device: {Config.DEVICE}")
    
    # Test forward pass
    print("\nTesting forward pass...")
    dummy_input = torch.randn(4, 3, Config.IMG_SIZE, Config.IMG_SIZE)
    with torch.no_grad():
        gender_out, identity_out = model(dummy_input)
    
    print(f"âœ“ Input shape: {dummy_input.shape}")
    print(f"âœ“ Gender output shape: {gender_out.shape}")
    print(f"âœ“ Identity output shape: {identity_out.shape}")
    
    # Test embeddings
    print("\nTesting feature embeddings...")
    with torch.no_grad():
        embeddings = model.get_embedding(dummy_input)
    print(f"âœ“ Embedding shape: {embeddings.shape}")
    print(f"âœ“ Embedding norm: {torch.norm(embeddings, dim=1).mean():.4f}")
    
    print("\nâœ… Model architecture demo completed!")
    return model

def demo_robust_augmentations():
    """Demonstrate robust augmentation pipeline"""
    print("\nğŸŒŸ Robust Augmentation Demo")
    print("=" * 60)
    
    from src.dataset import get_robust_transforms
    
    # Create sample image
    sample_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
    
    # Get transforms
    train_transform = get_robust_transforms('train', Config.IMG_SIZE)
    val_transform = get_robust_transforms('val', Config.IMG_SIZE)
    
    print("âœ“ Training augmentations:")
    for transform in train_transform.transforms:
        print(f"  - {transform.__class__.__name__}")
    
    print("âœ“ Validation transforms:")
    for transform in val_transform.transforms:
        print(f"  - {transform.__class__.__name__}")
    
    # Apply augmentations
    print("\nTesting augmentation pipeline...")
    augmented = train_transform(image=sample_image)
    print(f"âœ“ Input shape: {sample_image.shape}")
    print(f"âœ“ Output shape: {augmented['image'].shape}")
    
    print("\nâœ… Augmentation demo completed!")

def demo_sample_data():
    """Demonstrate sample data creation and loading"""
    print("\nğŸ“Š Sample Data Demo")
    print("=" * 60)
    
    # Create sample data
    print("Creating sample FACECOM dataset...")
    train_df, val_df, test_df = create_data_splits("data/sample_images")
    
    print(f"âœ“ Training samples: {len(train_df)}")
    print(f"âœ“ Validation samples: {len(val_df)}")
    print(f"âœ“ Test samples: {len(test_df)}")
    print(f"âœ“ Unique identities: {len(train_df.person_id.unique())}")
    print(f"âœ“ Gender distribution:")
    print(train_df.gender.value_counts().to_string())
    
    print("\nâœ… Sample data demo completed!")
    return len(train_df.person_id.unique())

def demo_inference_capabilities():
    """Demonstrate inference capabilities"""
    print("\nğŸ” Inference Capabilities Demo")
    print("=" * 60)
    
    # Note: This demo shows the inference interface
    # In practice, you would load a trained model
    
    print("Inference capabilities include:")
    print("âœ“ Single image prediction")
    print("âœ“ Batch prediction")
    print("âœ“ Feature embedding extraction")
    print("âœ“ Face comparison/verification")
    print("âœ“ Probability distributions")
    
    # Example inference code (would work with trained model)
    print("\nExample inference usage:")
    print("""
from inference import load_inference_model

# Load trained model
model = load_inference_model("checkpoints/ican_best_model.pth")

# Make prediction
result = model.predict("path/to/image.jpg", return_probabilities=True)
print(f"Gender: {result['gender']['prediction']}")
print(f"Identity: {result['identity']['prediction']}")

# Compare faces
comparison = model.compare_faces("image1.jpg", "image2.jpg")
print(f"Same person: {comparison['is_same_person']}")
    """)
    
    print("\nâœ… Inference demo completed!")

def demo_training_configuration():
    """Demonstrate training configuration options"""
    print("\nâš™ï¸  Training Configuration Demo")
    print("=" * 60)
    
    print(f"Model Configuration:")
    print(f"  Model Name: {Config.MODEL_NAME}")
    print(f"  Backbone: {Config.BACKBONE}")
    print(f"  Image Size: {Config.IMG_SIZE}")
    print(f"  Pretrained: {Config.PRETRAINED}")
    
    print(f"\nTraining Configuration:")
    print(f"  Batch Size: {Config.BATCH_SIZE}")
    print(f"  Learning Rate: {Config.LEARNING_RATE}")
    print(f"  Weight Decay: {Config.WEIGHT_DECAY}")
    print(f"  Max Epochs: {Config.NUM_EPOCHS}")
    print(f"  Early Stopping Patience: {Config.PATIENCE}")
    
    print(f"\nMulti-task Configuration:")
    print(f"  Gender Task Weight: {Config.GENDER_WEIGHT}")
    print(f"  Identity Task Weight: {Config.IDENTITY_WEIGHT}")
    print(f"  Final Score = {Config.GENDER_WEIGHT} Ã— Gender + {Config.IDENTITY_WEIGHT} Ã— Identity")
    
    print(f"\nAugmentation Configuration:")
    print(f"  Blur Probability: {Config.BLUR_PROB}")
    print(f"  Noise Probability: {Config.NOISE_PROB}")
    print(f"  Brightness Probability: {Config.BRIGHTNESS_PROB}")
    
    print("\nâœ… Configuration demo completed!")

def demo_robustness_features():
    """Demonstrate robustness features"""
    print("\nğŸ›¡ï¸  Robustness Features Demo")
    print("=" * 60)
    
    print("ICAN Robustness Features:")
    print("\n1. Adverse Condition Handling:")
    print("   âœ“ Motion blur resistance")
    print("   âœ“ Low-light performance")
    print("   âœ“ Weather condition adaptation (fog, rain)")
    print("   âœ“ Overexposure/glare handling")
    print("   âœ“ Noise robustness")
    
    print("\n2. Architectural Features:")
    print("   âœ“ Spatial attention mechanisms")
    print("   âœ“ Condition-adaptive blocks")
    print("   âœ“ Multi-scale feature extraction")
    print("   âœ“ Residual connections")
    print("   âœ“ Batch normalization")
    
    print("\n3. Training Techniques:")
    print("   âœ“ Multi-task learning")
    print("   âœ“ Data augmentation")
    print("   âœ“ Label smoothing")
    print("   âœ“ Gradient clipping")
    print("   âœ“ Early stopping")
    
    print("\n4. Evaluation Metrics:")
    print("   âœ“ Cross-validation")
    print("   âœ“ Condition-specific evaluation")
    print("   âœ“ Top-k accuracy")
    print("   âœ“ Confusion matrices")
    print("   âœ“ ROC curves")
    
    print("\nâœ… Robustness features demo completed!")

def main():
    """Run complete ICAN demo"""
    print("ğŸŒŸ" * 30)
    print("ICAN - Intelligent Condition-Adaptive Network")
    print("Robust Face Recognition and Gender Classification Demo")
    print("ğŸŒŸ" * 30)
    
    try:
        # 1. Model Architecture Demo
        model = demo_model_architecture()
        
        # 2. Augmentation Demo
        demo_robust_augmentations()
        
        # 3. Sample Data Demo
        num_identities = demo_sample_data()
        
        # 4. Training Configuration Demo
        demo_training_configuration()
        
        # 5. Robustness Features Demo
        demo_robustness_features()
        
        # 6. Inference Demo
        demo_inference_capabilities()
        
        # Final Summary
        print("\nğŸ‰ ICAN Demo Summary")
        print("=" * 60)
        print("âœ… All demos completed successfully!")
        print(f"ğŸ—ï¸  Model: {Config.MODEL_NAME} with {count_parameters(model):,} parameters")
        print(f"ğŸ“Š Sample dataset: {num_identities} identities")
        print(f"ğŸ›¡ï¸  Robust to: blur, fog, rain, low-light, overexposure")
        print(f"ğŸ¯ Tasks: Gender classification + Face recognition")
        print(f"âš¡ Ready for training and inference!")
        
        print("\nğŸš€ Next Steps:")
        print("1. Prepare your FACECOM dataset")
        print("2. Run: python main.py --epochs 10 --batch_size 16 (for quick test)")
        print("3. For full training: python main.py")
        print("4. For inference: python inference.py --image your_image.jpg")
        
        print("\nğŸ“š For more information, see README.md")
        
    except Exception as e:
        print(f"\nâŒ Demo failed with error: {str(e)}")
        import traceback
        traceback.print_exc()
        
    print("\n" + "ğŸŒŸ" * 30)

if __name__ == "__main__":
    main() 